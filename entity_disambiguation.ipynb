{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Disambiguation with an all-Born pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally tackle our target problem, i.e., entity disambiguation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "\n",
    "from wiki_tools import get_data_from_snippets\n",
    "from utils import get_latest_model, process_doc, LogitsBorn, encode_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import random\n",
    "\n",
    "def process_text_snips(nlp, d, entity=None, disambig_key=None):\n",
    "    if isinstance(d, dict):\n",
    "        dfs = []\n",
    "        for k, v in d.items():\n",
    "            if entity is None:\n",
    "                # top level, so k is the entity name\n",
    "                df = process_text_snips(nlp, v, entity=k)\n",
    "            else:\n",
    "                # inside an entity, so k is the disambig key\n",
    "                df = process_text_snips(nlp, v, entity=entity, disambig_key=k)\n",
    "            dfs.append(df)\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    elif isinstance(d, list):\n",
    "        dfs = [process_text_snips(nlp, item, entity=entity, disambig_key=disambig_key) for item in d]\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    elif isinstance(d, str):\n",
    "        doc = nlp(d)\n",
    "        processed = process_doc(doc)\n",
    "        df = pd.DataFrame(processed)\n",
    "        df['entity'] = entity\n",
    "        df['disambig_key'] = disambig_key\n",
    "        return df\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def construct_traintest_dataframe(nlp, target_entity, data_dict, train_size=50):\n",
    "    n_disambigs_target = len(data_dict[target_entity])\n",
    "    valid_ents = [\n",
    "        ent for ent in data_dict.keys() \n",
    "        if (ent != target_entity) and (len(data_dict[ent]) >= n_disambigs_target)\n",
    "    ]\n",
    "    \n",
    "    if train_size:\n",
    "        # if a training size is specified, only choose enough entities to match it\n",
    "        valid_ents = random.sample(valid_ents, min(train_size, len(valid_ents)))\n",
    "    valid_ents.append(target_entity)  # include the target entity to process it\n",
    "    \n",
    "    train_dict = {}\n",
    "    for ent in valid_ents:\n",
    "        # we want the same number of disambiguations for each entity in the training set\n",
    "        train_dict[ent] = dict(islice(data_dict[ent].items(), n_disambigs_target))\n",
    "    \n",
    "    df = process_text_snips(nlp, train_dict)\n",
    "    \n",
    "    disambig_index_map = {\n",
    "        entity: {key: idx for idx, key in enumerate(sorted(df[df['entity'] == entity]['disambig_key'].unique()))}\n",
    "        for entity in df['entity'].unique()\n",
    "    }\n",
    "    \n",
    "    df['disambig_label'] = df.apply(lambda row: disambig_index_map[row['entity']][row['disambig_key']], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = get_data_from_snippets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first choose a target entity to disambiguate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scorpion'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_entity = random.choice(list(data_dict.keys()))\n",
    "target_entity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we collect a set of entities for training the disambiguating Born MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "traintest_df = construct_traintest_dataframe(nlp, target_entity, data_dict)\n",
    "traintest_df.drop('ner_tag', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>entity</th>\n",
       "      <th>disambig_key</th>\n",
       "      <th>disambig_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121512</th>\n",
       "      <td>0</td>\n",
       "      <td>five</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>Pluto</td>\n",
       "      <td>Disney</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39366</th>\n",
       "      <td>1</td>\n",
       "      <td>Niggas</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Jay-Z_and_Kanye_West_song</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132413</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "      <td>Byzantine</td>\n",
       "      <td>Byzantine_fault</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123328</th>\n",
       "      <td>3</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>cc</td>\n",
       "      <td>Pluto</td>\n",
       "      <td>mythology</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72027</th>\n",
       "      <td>4</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>pcomp</td>\n",
       "      <td>Faith</td>\n",
       "      <td>South_Korean_TV_series</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101601</th>\n",
       "      <td>0</td>\n",
       "      <td>Keawe</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>Kamehameha</td>\n",
       "      <td>Kamehameha_I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>2</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>Supernatural</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120501</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NUM</td>\n",
       "      <td>nummod</td>\n",
       "      <td>Isis</td>\n",
       "      <td>TV_series</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103374</th>\n",
       "      <td>1</td>\n",
       "      <td>increase</td>\n",
       "      <td>VERB</td>\n",
       "      <td>conj</td>\n",
       "      <td>Kamehameha</td>\n",
       "      <td>Kamehameha_Schools</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31970</th>\n",
       "      <td>0</td>\n",
       "      <td>film</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>attr</td>\n",
       "      <td>Spider</td>\n",
       "      <td>2002_film</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id     token    pos     dep      entity  \\\n",
       "121512            0      five    NUM  nummod       Pluto   \n",
       "39366             1    Niggas  PROPN    pobj       Paris   \n",
       "132413            0         ,  PUNCT   punct   Byzantine   \n",
       "123328            3       and  CCONJ      cc       Pluto   \n",
       "72027             4        of    ADP   pcomp       Faith   \n",
       "101601            0     Keawe  PROPN    pobj  Kamehameha   \n",
       "2697              2      Ruby  PROPN   nsubj        Ruby   \n",
       "120501            3        23    NUM  nummod        Isis   \n",
       "103374            1  increase   VERB    conj  Kamehameha   \n",
       "31970             0      film   NOUN    attr      Spider   \n",
       "\n",
       "                     disambig_key  disambig_label  \n",
       "121512                     Disney               0  \n",
       "39366   Jay-Z_and_Kanye_West_song               0  \n",
       "132413            Byzantine_fault               2  \n",
       "123328                  mythology               4  \n",
       "72027      South_Korean_TV_series               3  \n",
       "101601               Kamehameha_I               0  \n",
       "2697                 Supernatural               2  \n",
       "120501                  TV_series               3  \n",
       "103374         Kamehameha_Schools               2  \n",
       "31970                   2002_film               0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>entity</th>\n",
       "      <th>disambig_key</th>\n",
       "      <th>disambig_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Critical</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>Mortal_Kombat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>reception</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>Mortal_Kombat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>Mortal_Kombat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>poss</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>Mortal_Kombat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id      token   pos    dep    entity   disambig_key  \\\n",
       "0            0   Critical   ADJ   amod  Scorpion  Mortal_Kombat   \n",
       "1            0  reception  NOUN  nsubj  Scorpion  Mortal_Kombat   \n",
       "2            0         of   ADP   prep  Scorpion  Mortal_Kombat   \n",
       "3            0   Scorpion  NOUN   poss  Scorpion  Mortal_Kombat   \n",
       "\n",
       "   disambig_label  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = traintest_df[traintest_df['entity'] == target_entity].reset_index(drop=True)\n",
    "test_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = traintest_df[traintest_df['entity'] != target_entity].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>token</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>disambig_label</th>\n",
       "      <th>disambig_key</th>\n",
       "      <th>dep</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46322</th>\n",
       "      <td>Flower</td>\n",
       "      <td>(</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Japanese_group</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65463</th>\n",
       "      <td>Swamp</td>\n",
       "      <td>human</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>comic_book</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103207</th>\n",
       "      <td>Kamehameha</td>\n",
       "      <td>students</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Kamehameha_Schools</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122386</th>\n",
       "      <td>Pluto</td>\n",
       "      <td>October</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pluto_TV</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85994</th>\n",
       "      <td>Electra</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Pleiad</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity     token  sentence_id  disambig_label        disambig_key  \\\n",
       "46322       Flower         (            3               0      Japanese_group   \n",
       "65463        Swamp     human            1               4          comic_book   \n",
       "103207  Kamehameha  students            0               2  Kamehameha_Schools   \n",
       "122386       Pluto   October            0               2            Pluto_TV   \n",
       "85994      Electra         a            1               1              Pleiad   \n",
       "\n",
       "        dep  pos  \n",
       "46322    40   12  \n",
       "65463    34    7  \n",
       "103207   34    7  \n",
       "122386   34   11  \n",
       "85994    19    5  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_encode = set(train_df.columns) - {'sentence_id', 'token', 'entity', 'disambig_key', 'disambig_label'}\n",
    "enc_train_df, mappings = encode_categorical(train_df, cols_to_encode)\n",
    "enc_train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Becuase we already have the mappings, we can save some computation by simply re-using them (which we'd have to do anyhow to make sure to keep consistency between train and test data)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_categorical_mapping(prepared_df, mappings):\n",
    "    encoded_df = prepared_df.copy()\n",
    "    for col, mapping in mappings.items():\n",
    "        value_to_index = {value: index for index, value in enumerate(mapping)}\n",
    "        encoded_df[col] = prepared_df[col].map(value_to_index)\n",
    "        encoded_df[col] = encoded_df[col].fillna(len(mapping))\n",
    "        encoded_df[col] = encoded_df[col].astype(np.int8)\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep</th>\n",
       "      <th>entity</th>\n",
       "      <th>disambig_key</th>\n",
       "      <th>disambig_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>'s</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>Mortal_Kombat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>TV_series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>1</td>\n",
       "      <td>prestigious</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>horse</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>2</td>\n",
       "      <td>Macehead</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>Scorpion_II</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>Scorpion</td>\n",
       "      <td>TV_series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id        token  pos  dep    entity   disambig_key  \\\n",
       "76              1           's    9   11  Scorpion  Mortal_Kombat   \n",
       "819             1           is    3    0  Scorpion      TV_series   \n",
       "2660            1  prestigious    0    6  Scorpion          horse   \n",
       "1946            2     Macehead   11    8  Scorpion    Scorpion_II   \n",
       "1241            3           10    8   30  Scorpion      TV_series   \n",
       "\n",
       "      disambig_label  \n",
       "76                 0  \n",
       "819                2  \n",
       "2660               3  \n",
       "1946               1  \n",
       "1241               2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_test_df = apply_categorical_mapping(test_df, mappings)\n",
    "enc_test_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "born_clf = get_latest_model('clf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bored",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
